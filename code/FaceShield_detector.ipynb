{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceShield_detector.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SjYxzuJpGLA"
      },
      "source": [
        "!pip install mediapipe\n",
        "import mediapipe as mp \n",
        "import cv2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9b-ZwQ8pMmw"
      },
      "source": [
        "!pip install numpy\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym6WnT0Tpeun"
      },
      "source": [
        "HSV = [np.array([136, 87, 111], np.uint8), np.array([180, 255, 255], np.uint8),\n",
        "       np.array([25, 52, 72], np.uint8)  , np.array([76, 255, 255],  np.uint8),\n",
        "       np.array([94, 80, 2], np.uint8)   , np.array([150, 255, 255], np.uint8)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzEGazeypj6_"
      },
      "source": [
        "mpDraw = mp.solutions.drawing_utils\n",
        "mpFaceMesh = mp.solutions.face_mesh\n",
        "faceMesh = mpFaceMesh.FaceMesh(max_num_faces=2)\n",
        "drawSpec = mpDraw.DrawingSpec(thickness=1, circle_radius=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEcXB_1Ppnt6"
      },
      "source": [
        "def prespective(biggest,img):\n",
        "    scale = 1\n",
        "    pts1 = np.float32(biggest)  # PREPARE POINTS FOR WARP\n",
        "    highttrace = (biggest[1][1]-biggest[0][1])*scale\n",
        "    widthtrace = (biggest[2][0]-biggest[0][0])*scale\n",
        "    pts2 = np.float32([[0, 0],  [0, highttrace], [widthtrace, highttrace], [widthtrace, 0]])  # PREPARE POINTS FOR WARP\n",
        "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
        "    imgWarpColored = cv2.warpPerspective(img, matrix, (widthtrace, highttrace))\n",
        "    return imgWarpColored"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3pruiNHqKPk"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import numpy as np\n",
        "\n",
        "def init_camera():\n",
        "  \"\"\"Create objects and functions in HTML/JavaScript to access local web camera\"\"\"\n",
        "\n",
        "  js = Javascript('''\n",
        "\n",
        "    // global variables to use in both functions\n",
        "    var div = null;\n",
        "    var video = null;   // <video> to display stream from local webcam\n",
        "    var stream = null;  // stream from local webcam\n",
        "    var canvas = null;  // <canvas> for single frame from <video> and convert frame to JPG\n",
        "    var img = null;     // <img> to display JPG after processing with `cv2`\n",
        "\n",
        "    async function initCamera() {\n",
        "      // place for video (and eventually buttons)\n",
        "      div = document.createElement('div');\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      // <video> to display video\n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      div.appendChild(video);\n",
        "\n",
        "      // get webcam stream and assing to <video>\n",
        "      stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "      video.srcObject = stream;\n",
        "\n",
        "      // start playing stream from webcam in <video>\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // <canvas> for frame from <video>\n",
        "      canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      //div.appendChild(input_canvas); // there is no need to display to get image (but you can display it for test)\n",
        "\n",
        "      // <img> for image after processing with `cv2`\n",
        "      img = document.createElement('img');\n",
        "      img.width = video.videoWidth;\n",
        "      img.height = video.videoHeight;\n",
        "      div.appendChild(img);\n",
        "    }\n",
        "\n",
        "    async function takeImage(quality) {\n",
        "      // draw frame from <video> on <canvas>\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "      // stop webcam stream\n",
        "      //stream.getVideoTracks()[0].stop();\n",
        "\n",
        "      // get data from <canvas> as JPG image decoded base64 and with header \"data:image/jpg;base64,\"\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "      //return canvas.toDataURL('image/png', quality);\n",
        "    }\n",
        "\n",
        "    async function showImage(image) {\n",
        "      // it needs string \"data:image/jpg;base64,JPG-DATA-ENCODED-BASE64\"\n",
        "      // it will replace previous image in `<img src=\"\">`\n",
        "      img.src = image;\n",
        "      // TODO: create <img> if doesn't exists, \n",
        "      // TODO: use `id` to use different `<img>` for different image - like `name` in `cv2.imshow(name, image)`\n",
        "    }\n",
        "\n",
        "  ''')\n",
        "\n",
        "  display(js)\n",
        "  eval_js('initCamera()')\n",
        "\n",
        "def take_frame(quality=0.8):\n",
        "  \"\"\"Get frame from web camera\"\"\"\n",
        "\n",
        "  data = eval_js('takeImage({})'.format(quality))  # run JavaScript code to get image (JPG as string base64) from <canvas>\n",
        "\n",
        "  header, data = data.split(',')  # split header (\"data:image/jpg;base64,\") and base64 data (JPG)\n",
        "  data = b64decode(data)  # decode base64\n",
        "  data = np.frombuffer(data, dtype=np.uint8)  # create numpy array with JPG data\n",
        "\n",
        "  img = cv2.imdecode(data, cv2.IMREAD_UNCHANGED)  # uncompress JPG data to array of pixels\n",
        "\n",
        "  return img\n",
        "\n",
        "def show_frame(img, quality=0.8):\n",
        "  \"\"\"Put frame as <img src=\"data:image/jpg;base64,....\"> \"\"\"\n",
        "\n",
        "  ret, data = cv2.imencode('.jpg', img)  # compress array of pixels to JPG data\n",
        "\n",
        "  data = b64encode(data)  # encode base64\n",
        "  data = data.decode()  # convert bytes to string\n",
        "  data = 'data:image/jpg;base64,' + data  # join header (\"data:image/jpg;base64,\") and base64 data (JPG)\n",
        "\n",
        "  eval_js('showImage(\"{}\")'.format(data))  # run JavaScript code to put image (JPG as string base64) in <img>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_3d3Wp_qcKZ"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# init JavaScript code\n",
        "init_camera()\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        img = take_frame()\n",
        "\n",
        "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        results = faceMesh.process(imgRGB)\n",
        "        id067=id203=(0,0)\n",
        "        maxma = 0\n",
        "        mask = []\n",
        "        if results.multi_face_landmarks:\n",
        "            for faceLms in results.multi_face_landmarks:\n",
        "                # mpDraw.draw_landmarks(img, faceLms, mpFaceMesh.FACE_CONNECTIONS,drawSpec, drawSpec)\n",
        "                for id,lm in enumerate(faceLms.landmark):\n",
        "                    #print(lm)\n",
        "                    ih, iw, ic = img.shape\n",
        "                    x, y = int(lm.x * iw), int(lm.y * ih)\n",
        "                    # cv2.putText(img,str(id),(x,y),cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,0, 255))\n",
        "                    if(id == 67):\n",
        "                        id067 = (x,y)\n",
        "                    if(id == 293):\n",
        "                        id203 = (x,y)\n",
        "        if id067[1] > id203[1]:\n",
        "            pt1=id067\n",
        "            pt2=id203\n",
        "            id067 = (pt1[0],pt2[1])\n",
        "            id203 = (pt2[0],pt1[1])\n",
        "\n",
        "        array = [[id067[0],id067[1]], [id067[0], id203[1]], [id203[0], id203[1]], [id203[0], id067[1]]]\n",
        "        imageFrame = prespective(array,img)\n",
        "\n",
        "        hsvFrame = cv2.cvtColor(imageFrame, cv2.COLOR_BGR2HSV)\n",
        "        kernal = np.ones((5, 5), \"uint8\")\n",
        "        for i in range(3):\n",
        "            mask.append(cv2.inRange(hsvFrame, HSV[(i*2)], HSV[(i*2) + 1]))\n",
        "            m = cv2.dilate(mask[i], kernal)\n",
        "            red = cv2.bitwise_and(imageFrame, imageFrame, mask = m)\n",
        "            contours, hierarchy = cv2.findContours(m,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "            for pic, contour in enumerate(contours):\n",
        "                area = cv2.contourArea(contour)\n",
        "                if (area > 300):\n",
        "                    x, y, w, h = cv2.boundingRect(contour)\n",
        "                    imageFrame = cv2.rectangle(imageFrame, (x, y),(x + w, y + h),(0, 0, 255), 2)\n",
        "                    cv2.putText(img, \"Face Shield detected\", (id067[0] + x, id067[1] + y), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0))\n",
        "                    maxma = 1\n",
        "                    print(\"Face Shield detected\")\n",
        "        if(maxma==0):\n",
        "            cv2.putText(img, \"No shield detected\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0, 255))\n",
        "            print(\"No shield detected\")\n",
        "        \n",
        "        cv2_imshow(img)  # it creates new image for every frame (it doesn't replace previous image) so it is useless\n",
        "        show_frame(img)  # it replace previous image\n",
        "        \n",
        "    except Exception as err:\n",
        "        print('Exception:', err)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsG8AW6wuRkK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBF1c0r8uvwf"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5RolkDAyheQ"
      },
      "source": [
        "# from google.colab import files\n",
        "# files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd9e4vriuyiR"
      },
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF5OZb3Su_aw"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "try:\n",
        "\n",
        "  img = cv2.imread('/content/photo.jpg')\n",
        "  imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  results = faceMesh.process(imgRGB)\n",
        "  id067=id203=(0,0)\n",
        "  maxma = 0\n",
        "  mask = []\n",
        "  if results.multi_face_landmarks:\n",
        "      for faceLms in results.multi_face_landmarks:\n",
        "          # mpDraw.draw_landmarks(img, faceLms, mpFaceMesh.FACE_CONNECTIONS,drawSpec, drawSpec)\n",
        "          for id,lm in enumerate(faceLms.landmark):\n",
        "              #print(lm)\n",
        "              ih, iw, ic = img.shape\n",
        "              x, y = int(lm.x * iw), int(lm.y * ih)\n",
        "              # cv2.putText(img,str(id),(x,y),cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,0, 255))\n",
        "              if(id == 67):\n",
        "                  id067 = (x,y)\n",
        "              if(id == 293):\n",
        "                  id203 = (x,y)\n",
        "  if id067[1] > id203[1]:\n",
        "      pt1=id067\n",
        "      pt2=id203\n",
        "      id067 = (pt1[0],pt2[1])\n",
        "      id203 = (pt2[0],pt1[1])\n",
        "\n",
        "  array = [[id067[0],id067[1]], [id067[0], id203[1]], [id203[0], id203[1]], [id203[0], id067[1]]]\n",
        "  imageFrame = prespective(array,img)\n",
        "\n",
        "  hsvFrame = cv2.cvtColor(imageFrame, cv2.COLOR_BGR2HSV)\n",
        "  kernal = np.ones((5, 5), \"uint8\")\n",
        "  for i in range(3):\n",
        "      mask.append(cv2.inRange(hsvFrame, HSV[(i*2)], HSV[(i*2) + 1]))\n",
        "      m = cv2.dilate(mask[i], kernal)\n",
        "      red = cv2.bitwise_and(imageFrame, imageFrame, mask = m)\n",
        "      contours, hierarchy = cv2.findContours(m,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "      for pic, contour in enumerate(contours):\n",
        "          area = cv2.contourArea(contour)\n",
        "          if (area > 300):\n",
        "              x, y, w, h = cv2.boundingRect(contour)\n",
        "              imageFrame = cv2.rectangle(imageFrame, (x, y),(x + w, y + h),(0, 0, 255), 2)\n",
        "              cv2.putText(img, \"Face Shield detected\", (id067[0] + x, id067[1] + y), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0))\n",
        "              maxma = 1\n",
        "              print(\"Face Shield detected\")\n",
        "  if(maxma==0):\n",
        "      cv2.putText(img, \"No shield detected\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0, 255))\n",
        "      print(\" No Face Shield detected\")\n",
        "  cv2_imshow(img)\n",
        "\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}